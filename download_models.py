from sentence_transformers import SentenceTransformer
from transformers import AutoTokenizer, AutoModelForCausalLM
import os

# =============================
# SETUP FOLDER
# =============================
os.makedirs('./models', exist_ok=True)

print("=" * 60)
print("ƒêANG T·∫¢I AI MODELS OFFLINE...")
print("=" * 60)

# =============================
# 1) T·∫¢I EMBEDDING MODEL
# =============================
print("\n[1/2] T·∫£i Embedding Model (MiniLM)...")

embedding_model = SentenceTransformer("sentence-transformers/paraphrase-MiniLM-L6-v2")
embedding_model.save("./models/embedding_model")

print("‚úÖ Embedding Model xong!")


# =============================
# 2) T·∫¢I Qwen2.5-0.5B-INSTRUCT
# =============================
print("\n[2/2] T·∫£i LLM Model (Qwen2.5-0.5B-Instruct)...")
print("‚è∞ ƒê·ª£i 1‚Äì3 ph√∫t... (model nh·ªè n√™n t·∫£i nhanh)")

LLM_ID = "Qwen/Qwen2.5-0.5B-Instruct"
LLM_PATH = "./models/llm_model"

os.makedirs(LLM_PATH, exist_ok=True)

tokenizer = AutoTokenizer.from_pretrained(
    LLM_ID,
    trust_remote_code=True,
    local_files_only=False

)

model = AutoModelForCausalLM.from_pretrained(
    LLM_ID,
    trust_remote_code=True,
    local_files_only=True
)

tokenizer.save_pretrained(LLM_PATH)
model.save_pretrained(LLM_PATH)

print("‚úÖ Qwen 0.5B ƒë√£ t·∫£i xong!")
print("=" * 60)
print("üéâ M·ªçi th·ª© ƒë√£ s·∫µn s√†ng!")
print("=" * 60)
